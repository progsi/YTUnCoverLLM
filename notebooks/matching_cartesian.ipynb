{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching all pairs (Cartesian Product)\n",
    "\n",
    "This notebook addresses the following questions:\n",
    "- how do simple or fuzzy matching baselines perform when evaluated on CSI datasets?\n",
    "- evaluation metric: mean average precision (mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import pandas as pd\n",
    "from src.Utils import get_target_matrix\n",
    "\n",
    "# SHS100K\n",
    "data_shs = pd.read_parquet(\"/data/csi_datasets/shs100k2_yt.parquet\").set_index(\"yt_id\").query(\"split == 'TEST'\")\n",
    "left_shs = [\"title\"]\n",
    "right = [\"video_title\", \"description\"]\n",
    "\n",
    "# Da-Tacos\n",
    "data_datacos = pd.read_parquet(\"/data/csi_datasets/datacos_yt.parquet\").set_index(\"yt_id\")\n",
    "left_datacos = [\"title_perf\", \"title_work\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match without NER\n",
    "- simple string matching (lowercase)\n",
    "- fuzzy matching: token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Matcher import Matcher\n",
    "\n",
    "def string_match_lower(left_str: str, right_str: str, score_cutoff=None):\n",
    "    return float(left_str.lower() in right_str.lower())\n",
    "\n",
    "simple_matcher = Matcher(func=string_match_lower)\n",
    "fuzzy_matcher = Matcher(func=\"fuzz.token_ratio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match simple\n",
      "mAP Simple @ SHS100K-Test: 0.6909516453742981\n",
      "mAP Simple @ Da-Tacos: 0.7247956991195679\n",
      "Match fuzzy\n",
      "mAP Fuzzy @ SHS100K-Test: 0.6547946929931641\n",
      "mAP Fuzzy @ Da-Tacos: 0.6911440491676331\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.retrieval import RetrievalMAP\n",
    "import torch\n",
    "\n",
    "def compute_map(preds: torch.tensor, target: torch.tensor):\n",
    "    func = RetrievalMAP(empty_target_action=\"skip\")\n",
    "    m, n = target.shape\n",
    "    indexes = torch.arange(m).view(-1, 1).expand(-1, n)\n",
    "    return func(preds=preds, target=target, indexes=indexes)\n",
    "\n",
    "target_shs = get_target_matrix(data_shs)\n",
    "target_datacos = get_target_matrix(data_datacos)\n",
    "\n",
    "print(\"Match simple\")\n",
    "preds = simple_matcher.match_square(data_shs, left_shs, right)\n",
    "print(f\"mAP Simple @ SHS100K-Test: {compute_map(preds=torch.from_numpy(preds.values), target=target_shs)}\")\n",
    "\n",
    "preds = simple_matcher.match_square(data_datacos, [\"title_perf\"], right)\n",
    "print(f\"mAP Simple @ Da-Tacos: {compute_map(preds=torch.from_numpy(preds.values), target=target_datacos)}\")\n",
    "\n",
    "print(\"Match fuzzy\")\n",
    "preds = fuzzy_matcher.match_square(data_shs, left_shs, right)\n",
    "print(f\"mAP Fuzzy @ SHS100K-Test: {compute_map(preds=torch.from_numpy(preds.values), target=target_shs)}\")\n",
    "preds = fuzzy_matcher.match_square(data_datacos, left_datacos, right)\n",
    "print(f\"mAP Fuzzy @ Da-Tacos: {compute_map(preds=torch.from_numpy(preds.values), target=target_datacos)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching with NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHS100K\n",
    "data_shs = pd.read_parquet(\"../data/shs100k2_biotag.parquet\").set_index(\"yt_id\").query(\"split == 'TEST'\")\n",
    "data_shs.yt_processed = data_shs.yt_processed.str.replace(\"\\n\", \" \")\n",
    "\n",
    "left_shs = [\"title\"]\n",
    "right = [\"yt_processed\"]\n",
    "\n",
    "# Da-Tacos\n",
    "data_datacos = pd.read_parquet(\"../data/datacos_biotag.parquet\").set_index(\"yt_id\")\n",
    "data_datacos.yt_processed = data_datacos.yt_processed.str.replace(\"\\n\", \" \")\n",
    "left_datacos = [\"title_perf\", \"title_work\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER on SHS\n",
      "NER on Da-Tacos\n"
     ]
    }
   ],
   "source": [
    "from src.Wrapper import NER_Wrapper\n",
    "\n",
    "model_path = os.path.join(\"..\", \"baseline\", \"music-ner-eacl2023\", \"output\", \"datacos\", \"bert-large-uncased\", \"checkpoint-500\")\n",
    "ner_model = NER_Wrapper(model_path)\n",
    "\n",
    "print(\"NER on SHS\")\n",
    "data_shs = ner_model.concat_entities(data_shs, text_attrs=right, extract_attrs=left_shs)\n",
    "data_shs.to_parquet(\"../data/shs100k2_ner.parquet\")\n",
    "\n",
    "print(\"NER on Da-Tacos\")\n",
    "data_datacos = ner_model.concat_entities(data_datacos, text_attrs=right, extract_attrs=left_datacos)\n",
    "data_datacos.to_parquet(\"../data/datacos_ner.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER-Postprocessing\n",
    "- Concat extracted entities\n",
    "- consider full text if no entities found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_ner2(data: pd.DataFrame, attr: str):\n",
    "    \"\"\"Concat ner2 column to data which is used for matching step.\n",
    "    Args:\n",
    "        data (pd.DataFrame): input dataframe\n",
    "        attr (str): column name\n",
    "    Returns:\n",
    "        pd.DataFrame: output dataframe\n",
    "    \"\"\" \n",
    "    in_col = attr + '_ner'\n",
    "    out_col = in_col + str(2)\n",
    "    # transform list to concated string\n",
    "    data[out_col] = data[in_col].apply(lambda x: ' '.join(list(set(x))))\n",
    "\n",
    "    # replace empty strings with unfiltered metadata\n",
    "    extracted_is_empty = data[out_col].apply(lambda x: x == \"\")\n",
    "    data.loc[extracted_is_empty, out_col] = data.loc[extracted_is_empty, \"yt_processed\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "data_shs = concat_ner2(data_shs, \"title\")\n",
    "data_datacos = concat_ner2(data_datacos, \"title_perf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match simple\n",
      "mAP Simple @ SHS100K-Test: 0.733211874961853\n",
      "mAP Simple @ Da-Tacos: 0.7903980016708374\n",
      "Match fuzzy\n",
      "mAP Fuzzy @ SHS100K-Test: 0.8149332404136658\n",
      "mAP Fuzzy @ Da-Tacos: 0.783778727054596\n"
     ]
    }
   ],
   "source": [
    "target_shs = get_target_matrix(data_shs)\n",
    "target_datacos = get_target_matrix(data_datacos)\n",
    "\n",
    "left_shs = [\"title_processed\"]\n",
    "right_shs = [\"title_ner2\"]\n",
    "\n",
    "left_datacos = [\"title_perf_processed\"]\n",
    "right_datacos = [\"title_perf_ner2\"]\n",
    "\n",
    "print(\"Match simple\")\n",
    "preds = simple_matcher.match_square(data_shs, left_shs, right_shs)\n",
    "print(f\"mAP Simple @ SHS100K-Test: {compute_map(preds=torch.from_numpy(preds.values), target=target_shs)}\")\n",
    "\n",
    "preds = simple_matcher.match_square(data_datacos, [\"title_perf_processed\"], right_datacos)\n",
    "print(f\"mAP Simple @ Da-Tacos: {compute_map(preds=torch.from_numpy(preds.values), target=target_datacos)}\")\n",
    "\n",
    "print(\"Match fuzzy\")\n",
    "preds = fuzzy_matcher.match_square(data_shs, left_shs, right_shs)\n",
    "print(f\"mAP Fuzzy @ SHS100K-Test: {compute_map(preds=torch.from_numpy(preds.values), target=target_shs)}\")\n",
    "preds = fuzzy_matcher.match_square(data_datacos, [\"title_perf_processed\"], right_datacos)\n",
    "print(f\"mAP Fuzzy @ Da-Tacos: {compute_map(preds=torch.from_numpy(preds.values), target=target_datacos)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
