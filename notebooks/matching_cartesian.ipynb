{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching all pairs (Cartesian Product)\n",
    "\n",
    "This notebook addresses the following questions:\n",
    "- how do simple or fuzzy matching baselines perform when evaluated on CSI datasets?\n",
    "- evaluation metric: mean average precision (mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import pandas as pd\n",
    "from src.Utils import get_target_matrix\n",
    "\n",
    "# SHS100K\n",
    "data_shs = pd.read_parquet(\"/data/csi_datasets/shs100k2_yt.parquet\").set_index(\"yt_id\").query(\"split == 'TEST'\")\n",
    "left_shs = [\"title\"]\n",
    "right = [\"video_title\", \"description\"]\n",
    "\n",
    "# Da-Tacos\n",
    "data_datacos = pd.read_parquet(\"/data/csi_datasets/datacos_yt.parquet\").set_index(\"yt_id\")\n",
    "left_datacos = [\"title_perf\", \"title_work\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match without NER\n",
    "- simple string matching (lowercase)\n",
    "- fuzzy matching: token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Matcher import Matcher\n",
    "\n",
    "def string_match_lower(left_str: str, right_str: str, score_cutoff=None):\n",
    "    return float(left_str.lower() in right_str.lower())\n",
    "\n",
    "simple_matcher = Matcher(func=string_match_lower)\n",
    "fuzzy_matcher = Matcher(func=\"fuzz.token_ratio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match simple\n",
      "mAP Simple @ SHS100K-Test: 0.6909516453742981\n",
      "mAP Simple @ Da-Tacos: 0.7247956991195679\n",
      "Match fuzzy\n",
      "mAP Fuzzy @ SHS100K-Test: 0.6547946929931641\n",
      "mAP Fuzzy @ Da-Tacos: 0.6911440491676331\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.retrieval import RetrievalMAP\n",
    "import torch\n",
    "\n",
    "def compute_map(preds: torch.tensor, target: torch.tensor):\n",
    "    func = RetrievalMAP(empty_target_action=\"skip\")\n",
    "    m, n = target.shape\n",
    "    indexes = torch.arange(m).view(-1, 1).expand(-1, n)\n",
    "    return func(preds=preds, target=target, indexes=indexes)\n",
    "\n",
    "target_shs = get_target_matrix(data_shs)\n",
    "target_datacos = get_target_matrix(data_datacos)\n",
    "\n",
    "print(\"Match simple\")\n",
    "preds = simple_matcher.match_square(data_shs, left_shs, right)\n",
    "print(f\"mAP Simple @ SHS100K-Test: {compute_map(preds=torch.from_numpy(preds.values), target=target_shs)}\")\n",
    "\n",
    "preds = simple_matcher.match_square(data_datacos, [\"title_perf\"], right)\n",
    "print(f\"mAP Simple @ Da-Tacos: {compute_map(preds=torch.from_numpy(preds.values), target=target_datacos)}\")\n",
    "\n",
    "print(\"Match fuzzy\")\n",
    "preds = fuzzy_matcher.match_square(data_shs, left_shs, right)\n",
    "print(f\"mAP Fuzzy @ SHS100K-Test: {compute_map(preds=torch.from_numpy(preds.values), target=target_shs)}\")\n",
    "preds = fuzzy_matcher.match_square(data_datacos, left_datacos, right)\n",
    "print(f\"mAP Fuzzy @ Da-Tacos: {compute_map(preds=torch.from_numpy(preds.values), target=target_datacos)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching with NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHS100K\n",
    "data_shs = pd.read_parquet(\"../data/shs100k2_biotag.parquet\").set_index(\"yt_id\").query(\"split == 'TEST'\")\n",
    "data_shs.yt_processed = data_shs.yt_processed.str.replace(\"\\n\", \" \")\n",
    "\n",
    "left_shs = [\"title\"]\n",
    "right = [\"yt_processed\"]\n",
    "\n",
    "# Da-Tacos\n",
    "data_datacos = pd.read_parquet(\"../data/datacos_biotag.parquet\").set_index(\"yt_id\")\n",
    "data_datacos.yt_processed = data_datacos.yt_processed.str.replace(\"\\n\", \" \")\n",
    "left_datacos = [\"title_perf\", \"title_work\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER on SHS\n",
      "NER on Da-Tacos\n"
     ]
    }
   ],
   "source": [
    "from src.Wrapper import NER_Wrapper\n",
    "\n",
    "model_path = os.path.join(\"..\", \"baseline\", \"music-ner-eacl2023\", \"output\", \"datacos\", \"bert-large-uncased\", \"checkpoint-500\")\n",
    "ner_model = NER_Wrapper(model_path)\n",
    "\n",
    "print(\"NER on SHS\")\n",
    "data_shs = ner_model.concat_entities(data_shs, text_attrs=right, extract_attrs=left_shs)\n",
    "data_shs.to_parquet(\"../data/shs100k2_ner.parquet\")\n",
    "\n",
    "print(\"NER on Da-Tacos\")\n",
    "data_datacos = ner_model.concat_entities(data_datacos, text_attrs=right, extract_attrs=left_datacos)\n",
    "data_datacos.to_parquet(\"../data/datacos_ner.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match simple\n",
      "mAP Simple @ SHS100K-Test: 0.010427111759781837\n",
      "mAP Simple @ Da-Tacos: 0.7549802660942078\n",
      "Match fuzzy\n",
      "mAP Fuzzy @ SHS100K-Test: 0.2174900621175766\n",
      "mAP Fuzzy @ Da-Tacos: 0.2351095825433731\n"
     ]
    }
   ],
   "source": [
    "target_shs = get_target_matrix(data_shs)\n",
    "target_datacos = get_target_matrix(data_datacos)\n",
    "\n",
    "left_shs = [\"title_ner\"]\n",
    "left_datacos = [\"title_perf_ner\"]\n",
    "\n",
    "print(\"Match simple\")\n",
    "preds = simple_matcher.match_square(data_shs, left_shs, right)\n",
    "print(f\"mAP Simple @ SHS100K-Test: {compute_map(preds=torch.from_numpy(preds.values), target=target_shs)}\")\n",
    "\n",
    "preds = simple_matcher.match_square(data_datacos, [\"title_perf_processed\"], right)\n",
    "print(f\"mAP Simple @ Da-Tacos: {compute_map(preds=torch.from_numpy(preds.values), target=target_datacos)}\")\n",
    "\n",
    "print(\"Match fuzzy\")\n",
    "preds = fuzzy_matcher.match_square(data_shs, left_shs, right)\n",
    "print(f\"mAP Fuzzy @ SHS100K-Test: {compute_map(preds=torch.from_numpy(preds.values), target=target_shs)}\")\n",
    "preds = fuzzy_matcher.match_square(data_datacos, left_datacos, right)\n",
    "print(f\"mAP Fuzzy @ Da-Tacos: {compute_map(preds=torch.from_numpy(preds.values), target=target_datacos)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
