{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.Utils import read_jsonlines\n",
    "from src.Eval import get_iobs_from_data\n",
    "import os\n",
    "\n",
    "data = pd.read_parquet(\"../data/dataset/reddit+shsyt/data.parquet\").drop_duplicates(subset=\"id\")\n",
    "data[\"yt_id\"] = data.id.apply(lambda x: x.split(\"_\", 1)[1])\n",
    "\n",
    "\n",
    "data[\"has_WoA\"] = data.IOB.apply(lambda x: \"B-WoA\" in x)\n",
    "data[\"has_Artist\"] = data.IOB.apply(lambda x: \"B-Artist\" in x)\n",
    "data[\"index\"] = data.groupby(\"subset\").cumcount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>set_id</th>\n",
       "      <th>Origin</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>IOB</th>\n",
       "      <th>subset</th>\n",
       "      <th>yt_id</th>\n",
       "      <th>has_WoA</th>\n",
       "      <th>has_Artist</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8184</th>\n",
       "      <td>9373_D7pH8YSL_ac</td>\n",
       "      <td>9373.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>[[, pvhuru, ], banirabinzu, 「kids」, （, mgmt, c...</td>\n",
       "      <td>[O, O, O, B-Artist, B-WoA, O, B-Artist, O, O, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>D7pH8YSL_ac</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  set_id   Origin  \\\n",
       "8184  9373_D7pH8YSL_ac  9373.0  YouTube   \n",
       "\n",
       "                                                   TEXT  \\\n",
       "8184  [[, pvhuru, ], banirabinzu, 「kids」, （, mgmt, c...   \n",
       "\n",
       "                                                    IOB  subset        yt_id  \\\n",
       "8184  [O, O, O, B-Artist, B-WoA, O, B-Artist, O, O, ...       1  D7pH8YSL_ac   \n",
       "\n",
       "      has_WoA  has_Artist  index  \n",
       "8184     True        True     35  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data.subset == 1) & (data[\"index\"] == 35)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_shs = pd.read_json(\"../data/raw/shs100k_metadata.jsonl\", lines=True, orient=\"records\")\n",
    "data_shs = data_shs[['work_id', 'perf_id','perf_title', 'perf_artist']]\n",
    "data_shs.columns = pd.MultiIndex.from_product([[''], data_shs.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quentin tarantino', 'steven spielberg']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import sys\n",
    "sys.path.append(\"../preprocessing\")\n",
    "from Processor import PerformerStringPreprocessor\n",
    "from Utils import simplify_string, remove_bracket_with_one_content\n",
    "\n",
    "\n",
    "def get_title_variations(s: str) -> List[str]:\n",
    "    s = remove_bracket_with_one_content(s)\n",
    "    l = s.split(\"/\")\n",
    "    l = [simplify_string(s) for s in l]\n",
    "    return l\n",
    "\n",
    "performer_processor = PerformerStringPreprocessor()\n",
    "\n",
    "def get_performer_variations(s: str) -> List[str]:\n",
    "    l = performer_processor.split_performers(s)\n",
    "    l = [simplify_string(s) for s in l]\n",
    "    l = performer_processor.article_preprocessing(l)\n",
    "    return l\n",
    "\n",
    "get_performer_variations(\"quentin tarantino feat. steven spielberg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factual Memorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "_ = pd.read_json(\"../data/intermediate/shs100k2_memorization.jsonl\", lines=True, orient=\"records\")\n",
    "\n",
    "cols = []\n",
    "for c in _.columns:\n",
    "    new_c = ast.literal_eval(c)\n",
    "    if new_c[1] == '':\n",
    "        new_c = (new_c[1], new_c[0])\n",
    "    cols.append(new_c)\n",
    "\n",
    "_.columns = pd.MultiIndex.from_tuples(cols, names=[\"Model\", \"\"])\n",
    "_ = pd.merge(_, data_shs, \n",
    "                             how=\"left\", on=[(\"\", \"work_id\"), (\"\", \"perf_id\")])\n",
    "# _ = _[[c for c in _.columns if \"AW2\" not in c[1]]]\n",
    "_.columns = [(c[0], c[1].replace(\"AW3:\", \"AW2:\")) for c in _.columns]\n",
    "_ = _\n",
    "_.columns = pd.MultiIndex.from_tuples(_.columns, names=[\"Model\", \"\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>set_id</th>\n",
       "      <th>Origin</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>IOB</th>\n",
       "      <th>subset</th>\n",
       "      <th>yt_id</th>\n",
       "      <th>has_WoA</th>\n",
       "      <th>has_Artist</th>\n",
       "      <th>index</th>\n",
       "      <th>FireFunction-v2_Correctness</th>\n",
       "      <th>GPT-4o-mini_Correctness</th>\n",
       "      <th>Llama3.1-70B_Correctness</th>\n",
       "      <th>Llama3.1-8B_Correctness</th>\n",
       "      <th>Mixtral-8x22B_Correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21_L1-t3YvFH40</td>\n",
       "      <td>21.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>[gladys, knight, &amp;, the, pips, -, yesterday]</td>\n",
       "      <td>[B-Artist, I-Artist, O, B-Artist, I-Artist, O,...</td>\n",
       "      <td>5</td>\n",
       "      <td>L1-t3YvFH40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Both Correct</td>\n",
       "      <td>One Correct</td>\n",
       "      <td>Both Correct</td>\n",
       "      <td>Both Correct</td>\n",
       "      <td>Both Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21_L1-t3YvFH40</td>\n",
       "      <td>21.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>[gladys, knight, &amp;, the, pips, -, yesterday]</td>\n",
       "      <td>[B-Artist, I-Artist, O, B-Artist, I-Artist, O,...</td>\n",
       "      <td>5</td>\n",
       "      <td>L1-t3YvFH40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>One Correct</td>\n",
       "      <td>One Correct</td>\n",
       "      <td>One Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21_4SE8UvqaSWQ</td>\n",
       "      <td>21.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>[hooked, on, the, beatles, -, the, end]</td>\n",
       "      <td>[B-WoA, I-WoA, I-WoA, I-WoA, O, B-WoA, I-WoA]</td>\n",
       "      <td>5</td>\n",
       "      <td>4SE8UvqaSWQ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Both Correct</td>\n",
       "      <td>One Correct</td>\n",
       "      <td>Both Correct</td>\n",
       "      <td>Both Correct</td>\n",
       "      <td>Both Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21_4SE8UvqaSWQ</td>\n",
       "      <td>21.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>[hooked, on, the, beatles, -, the, end]</td>\n",
       "      <td>[B-WoA, I-WoA, I-WoA, I-WoA, O, B-WoA, I-WoA]</td>\n",
       "      <td>5</td>\n",
       "      <td>4SE8UvqaSWQ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>One Correct</td>\n",
       "      <td>One Correct</td>\n",
       "      <td>One Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58_hQz-aZH-ozU</td>\n",
       "      <td>58.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>[juan, rozoff, -, plaisir, d, amour]</td>\n",
       "      <td>[B-Artist, I-Artist, O, B-WoA, I-WoA, I-WoA]</td>\n",
       "      <td>1</td>\n",
       "      <td>hQz-aZH-ozU</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>One Correct</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>dataset4_709</td>\n",
       "      <td>12481.0</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>[songs, like, sub, urbams, cradle, ?]</td>\n",
       "      <td>[O, O, B-Artist, I-Artist, B-WoA, O]</td>\n",
       "      <td>3</td>\n",
       "      <td>709</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>dataset4_710</td>\n",
       "      <td>12482.0</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>[songs, /, artists, like, quarter, past, midni...</td>\n",
       "      <td>[O, O, O, O, B-WoA, I-WoA, I-WoA, O, B-Artist]</td>\n",
       "      <td>4</td>\n",
       "      <td>710</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>dataset4_711</td>\n",
       "      <td>12483.0</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>[soft, -, voiced, vocals]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "      <td>5</td>\n",
       "      <td>711</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>dataset4_712</td>\n",
       "      <td>12484.0</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>[find, me, music, with, dark, lyrics, covered,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>dataset4_713</td>\n",
       "      <td>12485.0</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>[looking, for, an, album, or, ep, in, cassette...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>713</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3124 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id   set_id   Origin  \\\n",
       "0     21_L1-t3YvFH40     21.0  YouTube   \n",
       "1     21_L1-t3YvFH40     21.0  YouTube   \n",
       "2     21_4SE8UvqaSWQ     21.0  YouTube   \n",
       "3     21_4SE8UvqaSWQ     21.0  YouTube   \n",
       "4     58_hQz-aZH-ozU     58.0  YouTube   \n",
       "...              ...      ...      ...   \n",
       "3119    dataset4_709  12481.0   Reddit   \n",
       "3120    dataset4_710  12482.0   Reddit   \n",
       "3121    dataset4_711  12483.0   Reddit   \n",
       "3122    dataset4_712  12484.0   Reddit   \n",
       "3123    dataset4_713  12485.0   Reddit   \n",
       "\n",
       "                                                   TEXT  \\\n",
       "0          [gladys, knight, &, the, pips, -, yesterday]   \n",
       "1          [gladys, knight, &, the, pips, -, yesterday]   \n",
       "2               [hooked, on, the, beatles, -, the, end]   \n",
       "3               [hooked, on, the, beatles, -, the, end]   \n",
       "4                  [juan, rozoff, -, plaisir, d, amour]   \n",
       "...                                                 ...   \n",
       "3119              [songs, like, sub, urbams, cradle, ?]   \n",
       "3120  [songs, /, artists, like, quarter, past, midni...   \n",
       "3121                          [soft, -, voiced, vocals]   \n",
       "3122  [find, me, music, with, dark, lyrics, covered,...   \n",
       "3123  [looking, for, an, album, or, ep, in, cassette...   \n",
       "\n",
       "                                                    IOB  subset        yt_id  \\\n",
       "0     [B-Artist, I-Artist, O, B-Artist, I-Artist, O,...       5  L1-t3YvFH40   \n",
       "1     [B-Artist, I-Artist, O, B-Artist, I-Artist, O,...       5  L1-t3YvFH40   \n",
       "2         [B-WoA, I-WoA, I-WoA, I-WoA, O, B-WoA, I-WoA]       5  4SE8UvqaSWQ   \n",
       "3         [B-WoA, I-WoA, I-WoA, I-WoA, O, B-WoA, I-WoA]       5  4SE8UvqaSWQ   \n",
       "4          [B-Artist, I-Artist, O, B-WoA, I-WoA, I-WoA]       1  hQz-aZH-ozU   \n",
       "...                                                 ...     ...          ...   \n",
       "3119               [O, O, B-Artist, I-Artist, B-WoA, O]       3          709   \n",
       "3120     [O, O, O, O, B-WoA, I-WoA, I-WoA, O, B-Artist]       4          710   \n",
       "3121                                       [O, O, O, O]       5          711   \n",
       "3122            [O, O, O, O, O, O, O, O, O, O, O, O, O]       1          712   \n",
       "3123  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       2          713   \n",
       "\n",
       "      has_WoA  has_Artist  index FireFunction-v2_Correctness  \\\n",
       "0        True        True      0                Both Correct   \n",
       "1        True        True      0                     Partial   \n",
       "2        True       False      1                Both Correct   \n",
       "3        True       False      1                     Partial   \n",
       "4        True        True      0                     Partial   \n",
       "...       ...         ...    ...                         ...   \n",
       "3119     True        True    599                         NaN   \n",
       "3120     True        True    590                         NaN   \n",
       "3121    False       False    592                         NaN   \n",
       "3122    False       False    593                         NaN   \n",
       "3123    False        True    598                         NaN   \n",
       "\n",
       "     GPT-4o-mini_Correctness Llama3.1-70B_Correctness Llama3.1-8B_Correctness  \\\n",
       "0                One Correct             Both Correct            Both Correct   \n",
       "1                    Partial              One Correct             One Correct   \n",
       "2                One Correct             Both Correct            Both Correct   \n",
       "3                    Partial              One Correct             One Correct   \n",
       "4                    Partial                  Partial             One Correct   \n",
       "...                      ...                      ...                     ...   \n",
       "3119                     NaN                      NaN                     NaN   \n",
       "3120                     NaN                      NaN                     NaN   \n",
       "3121                     NaN                      NaN                     NaN   \n",
       "3122                     NaN                      NaN                     NaN   \n",
       "3123                     NaN                      NaN                     NaN   \n",
       "\n",
       "     Mixtral-8x22B_Correctness  \n",
       "0                 Both Correct  \n",
       "1                  One Correct  \n",
       "2                 Both Correct  \n",
       "3                  One Correct  \n",
       "4                      Partial  \n",
       "...                        ...  \n",
       "3119                       NaN  \n",
       "3120                       NaN  \n",
       "3121                       NaN  \n",
       "3122                       NaN  \n",
       "3123                       NaN  \n",
       "\n",
       "[3124 rows x 15 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for c in _.columns:\n",
    "    model = c[0]\n",
    "    if model != '' and model not in models:\n",
    "        models.append(model)\n",
    "\n",
    "        __ = _[model]\n",
    "\n",
    "        _aw_cols = [c for c in __.columns if c.startswith(\"AW\")]\n",
    "        _aw_cols_related = [c for c in _aw_cols if \"Related\" in c]\n",
    "        _aw_cols_correct = [c for c in _aw_cols if \"Correct\" in c]\n",
    "\n",
    "        def correctness(row):\n",
    "            if row[_aw_cols].T.sum() == 0:\n",
    "                return \"None\"\n",
    "            elif row[_aw_cols_correct].T.sum() >= 2:\n",
    "                return \"Both Correct\"\n",
    "            elif row[_aw_cols_correct].T.sum() == 1:\n",
    "                return \"One Correct\"\n",
    "            else:\n",
    "                return \"Partial\"\n",
    "            \n",
    "        _[(model, \"Correctness\")] = __.apply(correctness, axis=1)\n",
    "        _[(model, \"Correctness\")].value_counts()\n",
    "\n",
    "__ = _[[(\"\", \"set_id\")] + [(model, \"Correctness\") for model in models]]\n",
    "__.columns = [\"set_id\"] + [f\"{model}_Correctness\" for model in models]\n",
    "data_memorization = pd.merge(data, __, on=\"set_id\", how=\"left\")\n",
    "data_memorization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.read_json(\"../data/intermediate/shs100k2_exposure.jsonl\", lines=True, orient=\"records\")\n",
    "\n",
    "__ = pd.read_parquet(\"../data/raw/shs100k2_yt.parquet\")[[\"set_id\", \"yt_id\", \"title\", \"performer\"]]\n",
    "__.title = __.title.str.lower()\n",
    "__.performer = __.performer.str.lower()\n",
    "\n",
    "_map = __.set_index([\"set_id\", \"yt_id\"]).to_dict()\n",
    "data[\"title\"] = data.apply(lambda x: _map[\"title\"].get((x.set_id, x.yt_id)), axis=1)\n",
    "data[\"performer\"] = data.apply(lambda x: _map[\"performer\"].get((x.set_id, x.yt_id)), axis=1)\n",
    "\n",
    "\n",
    "_ = pd.concat(\n",
    "    [pd.merge(\n",
    "        data, \n",
    "        _.loc[_.Entity == \"WoA\"], \n",
    "        left_on=[\"set_id\", \"title\"], \n",
    "        right_on=[\"set_id\", \"name\"],\n",
    "        how=\"left\"),\n",
    "     pd.merge(\n",
    "         data, \n",
    "         _.loc[_.Entity == \"Artist\"], \n",
    "         left_on=[\"set_id\", \"performer\"], \n",
    "         right_on=[\"set_id\", \"name\"], \n",
    "         how=\"left\")]\n",
    ").drop(\"yt_id_y\", axis=1).rename(\n",
    "    columns={\"yt_id_x\": \"yt_id\"}).drop_duplicates(subset=[\"id\", \"Entity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "2024-09-15 12:51:35 matplotlib.backends.backend_pdf DEBUG: Assigning font /F1 = '/data/miniconda3/envs/torch21/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf'\n",
      "2024-09-15 12:51:35 matplotlib.backends.backend_pdf DEBUG: Embedding font /data/miniconda3/envs/torch21/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf.\n",
      "2024-09-15 12:51:35 matplotlib.backends.backend_pdf DEBUG: Writing TrueType font.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.histplot(_.dropna(subset=\"exposure_max\"), x=\"exposure_max\", hue=\"Entity\")\n",
    "plt.xlabel(\"Exposure in a subset of D-YT\")\n",
    "plt.savefig(\"../figures/hist_exposure_dataset.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exposure_Artist</th>\n",
       "      <th>exposure_WoA</th>\n",
       "      <th>name_Artist</th>\n",
       "      <th>name_WoA</th>\n",
       "      <th>sitelinks_Artist</th>\n",
       "      <th>sitelinks_WoA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009_1MuNPBL0hMg</td>\n",
       "      <td>1.008419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vsop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1026_Ng4uw6k2RVM</td>\n",
       "      <td>4.324027</td>\n",
       "      <td>1.008419</td>\n",
       "      <td>john kay</td>\n",
       "      <td>i'm movin' on</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1026_idphZ2fY_a0</td>\n",
       "      <td>5.012986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>duane eddy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102_O3mnspFrGj8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.965611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you'll never walk alone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102_nbkPuH9rjKs</td>\n",
       "      <td>4.852235</td>\n",
       "      <td>2.965611</td>\n",
       "      <td>trisha yearwood</td>\n",
       "      <td>you'll never walk alone</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>9840_1FEB2_ywkjU</td>\n",
       "      <td>2.301332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>margie joseph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>986_6XuJ0E1Qu_c</td>\n",
       "      <td>6.981762</td>\n",
       "      <td>1.008419</td>\n",
       "      <td>django reinhardt</td>\n",
       "      <td>fine and dandy</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>9912_nuJnW0ow4bY</td>\n",
       "      <td>3.822592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>little milton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>9960_wK63eUyk-iM</td>\n",
       "      <td>8.632872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>john travolta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>9_IZEZAua5KtY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.818509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>over the rainbow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  exposure_Artist  exposure_WoA       name_Artist  \\\n",
       "0    1009_1MuNPBL0hMg         1.008419           NaN              vsop   \n",
       "1    1026_Ng4uw6k2RVM         4.324027      1.008419          john kay   \n",
       "2    1026_idphZ2fY_a0         5.012986           NaN        duane eddy   \n",
       "3     102_O3mnspFrGj8              NaN      2.965611               NaN   \n",
       "4     102_nbkPuH9rjKs         4.852235      2.965611   trisha yearwood   \n",
       "..                ...              ...           ...               ...   \n",
       "389  9840_1FEB2_ywkjU         2.301332           NaN     margie joseph   \n",
       "390   986_6XuJ0E1Qu_c         6.981762      1.008419  django reinhardt   \n",
       "391  9912_nuJnW0ow4bY         3.822592           NaN     little milton   \n",
       "392  9960_wK63eUyk-iM         8.632872           NaN     john travolta   \n",
       "393     9_IZEZAua5KtY              NaN      2.818509               NaN   \n",
       "\n",
       "                    name_WoA  sitelinks_Artist  sitelinks_WoA  \n",
       "0                        NaN               1.0            NaN  \n",
       "1              i'm movin' on              21.0            1.0  \n",
       "2                        NaN              29.0            NaN  \n",
       "3    you'll never walk alone               NaN            9.0  \n",
       "4    you'll never walk alone              27.0            9.0  \n",
       "..                       ...               ...            ...  \n",
       "389                      NaN               5.0            NaN  \n",
       "390           fine and dandy              64.0            1.0  \n",
       "391                      NaN              16.0            NaN  \n",
       "392                      NaN             113.0            NaN  \n",
       "393         over the rainbow               NaN            8.0  \n",
       "\n",
       "[394 rows x 7 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exposure = _.pivot_table(index=['id'],\n",
    "                              columns='Entity',\n",
    "                              values=['name', 'sitelinks_max', 'exposure_max'],\n",
    "                              aggfunc='first').reset_index()\n",
    "data_exposure.columns = [\"id\", \"exposure_Artist\", \"exposure_WoA\", \"name_Artist\", \"name_WoA\", \"sitelinks_Artist\", \"sitelinks_WoA\"]\n",
    "data_exposure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "##### Join Factual Memorization & Wikidata Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_joint = pd.merge(data_memorization, data_exposure, on=\"id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../output/reddit+shsyt/\"\n",
    "\n",
    "def get_IOB_preds(output_path) -> pd.DataFrame:\n",
    "    \"\"\"Get multiindex dataframe with predicted IOB lists.\n",
    "    Args:\n",
    "        output_path (_type_): _description_\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    def remove_duplicates(input_list):\n",
    "        seen = set()\n",
    "        return [x for x in input_list if not (x[\"text\"] in seen or seen.add(x[\"text\"]))]\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for model in os.listdir(output_path):\n",
    "        for f in os.listdir(os.path.join(output_path, model)):\n",
    "            _ = f.split(\".\")[0].split(\"_\")\n",
    "            dataset, k = _[0], int(_[1].replace(\"shot\", \"\"))\n",
    "            sampling = _[2] if len(_) > 2 else \"\"\n",
    "\n",
    "            preds = read_jsonlines(os.path.join(output_path, model, f))\n",
    "            _data = pd.DataFrame(preds).set_index(\"text\")\n",
    "            _, pred_iobs = get_iobs_from_data(preds)\n",
    "            _data[\"IOB_pred\"] = pred_iobs\n",
    "            _data =  _data.loc[~_data.index.duplicated(keep=\"first\"),[\"IOB_pred\"]]\n",
    "            \n",
    "            _data.columns =  pd.MultiIndex.from_product([[model], [k], [sampling]])\n",
    "\n",
    "            _new_cols = _data.columns.difference(data.columns)\n",
    "    \n",
    "            if not _new_cols.empty:\n",
    "                data = pd.concat([data, _data[_new_cols]], axis=1, join='outer')\n",
    "            else:\n",
    "                data = data.combine_first(_data)\n",
    "    \n",
    "    return data\n",
    "         \n",
    "preds = get_IOB_preds(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    gladys knight & the pips - yesterday\n",
       "1                    gladys knight & the pips - yesterday\n",
       "2                         hooked on the beatles - the end\n",
       "3                         hooked on the beatles - the end\n",
       "4                           juan rozoff - plaisir d amour\n",
       "                              ...                        \n",
       "3119                       songs like sub urbams cradle ?\n",
       "3120    songs / artists like quarter past midnight by ...\n",
       "3121                                 soft - voiced vocals\n",
       "3122    find me music with dark lyrics covered by an u...\n",
       "3123    looking for an album or ep in cassette tape fo...\n",
       "Name: TEXT, Length: 3124, dtype: object"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_joint2 = data_joint.set_index(\n",
    "    data_joint.TEXT.apply(' '.join)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 13:54:32 root INFO: Imported 302 predictions for 302 true examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 13:54:32 root INFO: Imported 99 predictions for 99 true examples\n",
      "2024-09-15 13:54:32 root INFO: Imported 290 predictions for 290 true examples\n",
      "2024-09-15 13:54:32 root INFO: Imported 60 predictions for 60 true examples\n",
      "2024-09-15 13:54:32 root INFO: Imported 123 predictions for 123 true examples\n",
      "2024-09-15 13:54:32 root INFO: Imported 36 predictions for 36 true examples\n",
      "2024-09-15 13:54:32 root INFO: Imported 101 predictions for 101 true examples\n",
      "2024-09-15 13:54:32 root INFO: Imported 36 predictions for 36 true examples\n",
      "2024-09-15 13:54:32 root INFO: Imported 321 predictions for 321 true examples\n",
      "2024-09-15 13:54:33 root INFO: Imported 214 predictions for 214 true examples\n",
      "2024-09-15 13:54:33 root INFO: Imported 49 predictions for 49 true examples\n",
      "2024-09-15 13:54:33 root INFO: Imported 45 predictions for 45 true examples\n",
      "2024-09-15 13:54:33 root INFO: Imported 388 predictions for 388 true examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping for (None, 35, 'tfidf')\n",
      "Skipping for (None, 35, 'tfidf')\n",
      "Skipping for (None, 35, 'tfidf')\n",
      "Skipping for (None, 35, 'tfidf')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 13:54:33 root INFO: Imported 252 predictions for 252 true examples\n",
      "2024-09-15 13:54:33 root INFO: Imported 65 predictions for 65 true examples\n",
      "2024-09-15 13:54:33 root INFO: Imported 46 predictions for 46 true examples\n",
      "/tmp/ipykernel_3050184/3876496025.py:54: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  return data.stack(level=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">FireFunction-v2</th>\n",
       "      <th colspan=\"4\" halign=\"left\">GPT-4o-mini</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Llama3.1-70B</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Mixtral-8x22B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">overall</th>\n",
       "      <th>Artist</th>\n",
       "      <th>WoA</th>\n",
       "      <th colspan=\"2\" halign=\"left\">overall</th>\n",
       "      <th>Artist</th>\n",
       "      <th>WoA</th>\n",
       "      <th colspan=\"2\" halign=\"left\">overall</th>\n",
       "      <th>Artist</th>\n",
       "      <th>WoA</th>\n",
       "      <th colspan=\"2\" halign=\"left\">overall</th>\n",
       "      <th>Artist</th>\n",
       "      <th>WoA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">strict</th>\n",
       "      <th>strict</th>\n",
       "      <th>strict</th>\n",
       "      <th colspan=\"2\" halign=\"left\">strict</th>\n",
       "      <th>strict</th>\n",
       "      <th>strict</th>\n",
       "      <th colspan=\"2\" halign=\"left\">strict</th>\n",
       "      <th>strict</th>\n",
       "      <th>strict</th>\n",
       "      <th colspan=\"2\" halign=\"left\">strict</th>\n",
       "      <th>strict</th>\n",
       "      <th>strict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>macro</th>\n",
       "      <th>macro</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>macro</th>\n",
       "      <th>macro</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>macro</th>\n",
       "      <th>macro</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>macro</th>\n",
       "      <th>macro</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>Both Correct</th>\n",
       "      <td>0.778126</td>\n",
       "      <td>0.735976</td>\n",
       "      <td>0.784452</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.863646</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.787255</td>\n",
       "      <td>0.762224</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.769481</td>\n",
       "      <td>0.830619</td>\n",
       "      <td>0.796397</td>\n",
       "      <td>0.784574</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.650418</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.760369</td>\n",
       "      <td>0.688160</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.698428</td>\n",
       "      <td>0.647143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One Correct</th>\n",
       "      <td>0.801598</td>\n",
       "      <td>0.753937</td>\n",
       "      <td>0.831615</td>\n",
       "      <td>0.676259</td>\n",
       "      <td>0.797301</td>\n",
       "      <td>0.763195</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.774704</td>\n",
       "      <td>0.741917</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.708134</td>\n",
       "      <td>0.811623</td>\n",
       "      <td>0.777626</td>\n",
       "      <td>0.851695</td>\n",
       "      <td>0.703557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial</th>\n",
       "      <td>0.810955</td>\n",
       "      <td>0.758550</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.790747</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.812743</td>\n",
       "      <td>0.783801</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.745516</td>\n",
       "      <td>0.706657</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               FireFunction-v2                               GPT-4o-mini  \\\n",
       "                       overall              Artist       WoA     overall   \n",
       "                        strict              strict    strict      strict   \n",
       "                            f1    recall    recall    recall          f1   \n",
       "                         macro     macro       NaN       NaN       macro   \n",
       "0 Both Correct        0.778126  0.735976  0.784452  0.687500    0.863646   \n",
       "  None                0.690476  0.650418  0.765625  0.535211    0.760369   \n",
       "  One Correct         0.801598  0.753937  0.831615  0.676259    0.797301   \n",
       "  Partial             0.810955  0.758550  0.840909  0.676190    0.825000   \n",
       "\n",
       "                                             Llama3.1-70B                      \\\n",
       "                            Artist       WoA      overall              Artist   \n",
       "                            strict    strict       strict              strict   \n",
       "                  recall    recall    recall           f1    recall    recall   \n",
       "                   macro       NaN       NaN        macro     macro       NaN   \n",
       "0 Both Correct  0.857143  0.877551  0.836735     0.787255  0.762224  0.754967   \n",
       "  None          0.688160  0.735294  0.641026     0.698428  0.647143  0.714286   \n",
       "  One Correct   0.763195  0.780488  0.745902     0.774704  0.741917  0.775701   \n",
       "  Partial       0.790747  0.870968  0.710526     0.812743  0.783801  0.755102   \n",
       "\n",
       "                         Mixtral-8x22B                                \n",
       "                     WoA       overall              Artist       WoA  \n",
       "                  strict        strict              strict    strict  \n",
       "                  recall            f1    recall    recall    recall  \n",
       "                     NaN         macro     macro       NaN       NaN  \n",
       "0 Both Correct  0.769481      0.830619  0.796397  0.784574  0.808219  \n",
       "  None          0.580000      0.754167  0.713333  0.760000  0.666667  \n",
       "  One Correct   0.708134      0.811623  0.777626  0.851695  0.703557  \n",
       "  Partial       0.812500      0.745516  0.706657  0.796875  0.616438  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.Eval import compute_results\n",
    "from contextlib import redirect_stdout\n",
    "import re\n",
    "\n",
    "\n",
    "def get_model_pred_col(pred_df: pd.DataFrame, model: str) -> str:\n",
    "    level_values = pred_df.columns.get_level_values(level=0)\n",
    "    if model.lower() in level_values:\n",
    "        return model.lower()\n",
    "    elif model.replace(\"-\", \":\").lower() in level_values:\n",
    "        return model.replace(\"-\", \":\").lower()\n",
    "    return None\n",
    "\n",
    "def suppress_output(func, *args, **kwargs):\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        with redirect_stdout(fnull):\n",
    "            return func(*args, **kwargs)      \n",
    "\n",
    "def get_results_per_factual_memorization_cls(k, sampling):\n",
    "    \n",
    "    correctness_cols = [c for c in data_joint.columns if \"_Correctness\" in c]\n",
    "    results = {}   \n",
    "\n",
    "    data_joint2 = data_joint.set_index(\n",
    "        data_joint.TEXT.apply(' '.join)\n",
    "    )\n",
    "\n",
    "    for correctness_col in correctness_cols:\n",
    "        model = correctness_col.split(\"_\")[0]\n",
    "\n",
    "        col = (get_model_pred_col(preds, model), k, sampling)\n",
    "\n",
    "        results[model] = {}\n",
    "        for group in data_joint[correctness_col].dropna().unique():\n",
    "            try:\n",
    "                _data = data_joint2.loc[data_joint2[correctness_col] == group].join(\n",
    "                    preds.loc[:,col].rename(\"IOB_pred\"), how=\"inner\").dropna(subset=[\"IOB\", \"IOB_pred\"])\n",
    "                iob_true = _data.IOB.values\n",
    "                iob_pred = _data.IOB_pred.values\n",
    "                results[model][group] = {}\n",
    "\n",
    "                kwargs = {\"true_labels\": iob_true, \"true_predictions\": iob_pred}\n",
    "                values = suppress_output(compute_results, **kwargs)\n",
    "                metrics = [\"overall_strict_f1_macro\", \"overall_strict_recall_macro\", \"Artist_strict_recall\", \"WoA_strict_recall\"]\n",
    "                for metric in metrics:\n",
    "                    results[model][group][metric] = values[metric]\n",
    "            except:\n",
    "                print(f\"Skipping for {col}\")\n",
    "\n",
    "    data = pd.json_normalize(results, sep='_')\n",
    "    data.columns = pd.MultiIndex.from_tuples([tuple(col.split('_')) for col in data.columns])\n",
    "    return data.stack(level=1)\n",
    "\n",
    "k = 35\n",
    "sampling = \"tfidf\"\n",
    "get_results_per_factual_memorization_cls(k, sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset  index\n",
       "5       0                     gladys knight & the pips - yesterday\n",
       "        1                          hooked on the beatles - the end\n",
       "1       0                            juan rozoff - plaisir d amour\n",
       "        1                           ub40 cant help falling in love\n",
       "        2         pearl jam - i cant help falling in love with you\n",
       "                                       ...                        \n",
       "3       599                         songs like sub urbams cradle ?\n",
       "4       590      songs / artists like quarter past midnight by ...\n",
       "5       592                                   soft - voiced vocals\n",
       "1       593      find me music with dark lyrics covered by an u...\n",
       "2       598      looking for an album or ep in cassette tape fo...\n",
       "Name: TEXT, Length: 2976, dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_joint.TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 12:02:21 root INFO: Imported 296 predictions for 296 true examples\n",
      "2024-09-15 12:02:21 root INFO: Imported 150 predictions for 150 true examples\n",
      "2024-09-15 12:02:21 root INFO: Imported 67 predictions for 67 true examples\n",
      "2024-09-15 12:02:21 root INFO: Imported 104 predictions for 104 true examples\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('gpt-4o-mini', 35, 'tfidf')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3053\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:776\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2152\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2176\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 123",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_tuples([\u001b[38;5;28mtuple\u001b[39m(col\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mstack(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mget_results_exposure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mget_results_exposure\u001b[0;34m(k, sampling, exposure_threshold)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     mask \u001b[38;5;241m=\u001b[39m data_joint[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexposure_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m exposure_threshold\n\u001b[1;32m     17\u001b[0m _data \u001b[38;5;241m=\u001b[39m data_joint\u001b[38;5;241m.\u001b[39mloc[mask]\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOB_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m), how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOB_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexposure_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     19\u001b[0m iob_true \u001b[38;5;241m=\u001b[39m _data\u001b[38;5;241m.\u001b[39mIOB\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     20\u001b[0m iob_pred \u001b[38;5;241m=\u001b[39m _data\u001b[38;5;241m.\u001b[39mIOB_pred\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/indexing.py:1368\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1367\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1371\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/indexing.py:1041\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# we may have a nested tuples indexer here\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_nested_tuple_indexer(tup):\n\u001b[0;32m-> 1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_nested_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# we maybe be using a tuple to represent multiple dimensions here\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m ax0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_nested_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     axis \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1153\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m axis \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# if we have a scalar, we are done\u001b[39;00m\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/generic.py:4287\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_level:\n\u001b[0;32m-> 4287\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4288\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/frame.py:4101\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[1;32m   4100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 4101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4102\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/frame.py:4159\u001b[0m, in \u001b[0;36mDataFrame._getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   4158\u001b[0m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[0;32m-> 4159\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m   4161\u001b[0m         new_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[loc]\n",
      "File \u001b[0;32m/data/miniconda3/envs/torch21/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3055\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3054\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;66;03m# e.g. test_partial_slicing_with_multiindex partial string slicing\u001b[39;00m\n\u001b[1;32m   3058\u001b[0m     loc, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loc_level(key, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels)))\n",
      "\u001b[0;31mKeyError\u001b[0m: ('gpt-4o-mini', 35, 'tfidf')"
     ]
    }
   ],
   "source": [
    "def get_results_exposure(k, sampling, exposure_threshold):\n",
    "\n",
    "    results = {}   \n",
    "\n",
    "    for model in preds.columns.get_level_values(level=0).unique():\n",
    "        col = (model, k, sampling)\n",
    "        if not results.get(model):\n",
    "            results[model] = {}\n",
    "\n",
    "        for group in [\"seen\", \"unseen\"]:\n",
    "            for cls in [\"Artist\", \"WoA\"]:\n",
    "                if group == \"seen\":\n",
    "                    mask = data_joint[f\"exposure_{cls}\"] >= exposure_threshold\n",
    "                else:\n",
    "                    mask = data_joint[f\"exposure_{cls}\"].fillna(0) < exposure_threshold\n",
    "\n",
    "                _data = data_joint.loc[mask].join(\n",
    "                    preds.loc[:,col].rename(\"IOB_pred\"), how=\"inner\").dropna(subset=[\"IOB\", \"IOB_pred\", f\"exposure_{cls}\"])\n",
    "                iob_true = _data.IOB.values\n",
    "                iob_pred = _data.IOB_pred.values\n",
    "\n",
    "                if not results[model].get(cls):\n",
    "                    results[model][cls] = {}\n",
    "                if not results[model][cls].get(group):\n",
    "                    results[model][cls][group] = {}\n",
    "\n",
    "                kwargs = {\"true_labels\": iob_true, \"true_predictions\": iob_pred}\n",
    "                values = suppress_output(compute_results, **kwargs)\n",
    "                metrics = [\"Artist_strict_recall\", \"WoA_strict_recall\"]\n",
    "                for metric in metrics:\n",
    "                    if \"overall_\" in metric or cls + '_' in metric:\n",
    "                        results[model][cls][group][metric.split(\"_\")[-1]] = values[metric]\n",
    "\n",
    "    data = pd.json_normalize(results, sep='_')\n",
    "    data.columns = pd.MultiIndex.from_tuples([tuple(col.split('_')) for col in data.columns])\n",
    "    return data.stack(level=2)\n",
    "\n",
    "get_results_exposure(k, sampling, 1.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
