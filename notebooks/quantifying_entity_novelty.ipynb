{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying Entity Novelty\n",
    "- Exposure (see Carlini et al. 2019)\n",
    "- Factual Test\n",
    "- Utilization of a music entities published after the knowledge cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path_exposure = \"../data/intermediate/shs100k2_exposure.jsonl\"\n",
    "path_memorizations = \"../output/memorization2\"\n",
    "\n",
    "data_wd = pd.read_json(path_exposure, lines=True, orient=\"records\")\n",
    "\n",
    "data_perfs = pd.read_parquet(\"../data/raw/shs100k2_yt.parquet\")[\n",
    "    [\"set_id\", \"title\", \"performer\"]].groupby(\"set_id\", as_index=False).agg(list)\n",
    "\n",
    "__ = []\n",
    "files = os.listdir(path_memorizations)\n",
    "for f in files:\n",
    "    __data = pd.read_json(os.path.join(path_memorizations, f), lines=True, orient=\"records\")\n",
    "    if \"set_id\" in __data.columns:\n",
    "        __data = pd.merge(__data, data_perfs, how=\"left\", on=\"set_id\")\n",
    "        __data[\"filename\"] = f\n",
    "        __.append(__data)\n",
    "\n",
    "data = pd.concat(__)\n",
    "data[\"Model\"] = data.filename.str.replace(\n",
    "    \"llama3.1-70b.jsonl\", \"Llama3.1-70B\").str.replace(\n",
    "        \"llama3.1-8b.jsonl\", \"Llama3.1-8B\")\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../preprocessing\")\n",
    "from Processor import PerformerStringPreprocessor\n",
    "from Utils import (unicode_normalize, remove_brackets_and_all_content, \n",
    "                   remove_bracket_only, replace_linebreaks_tabs)\n",
    "processing_attrs = [\"artist_original\", \"artist_perf\", \"composer\"]\n",
    "preprocessor = PerformerStringPreprocessor()\n",
    "\n",
    "\n",
    "def preprocessing(s: str) -> str:\n",
    "        s = unicode_normalize(s)\n",
    "        # remove brackets with one-word content eg \"[us]\"\n",
    "        s = remove_brackets_and_all_content(s)\n",
    "        # remove brackets but keep content, eg. when (feat. Metallica) keep feat. Metallica\n",
    "        s = remove_bracket_only(s)\n",
    "        # split performers by defined separators\n",
    "        l = preprocessor.split_performers(replace_linebreaks_tabs(s))\n",
    "        # also consider performer names without artists\n",
    "        l = preprocessor.article_preprocessing(l)\n",
    "        return ','.join(l)\n",
    "\n",
    "data.artist_original = data.artist_original.apply(lambda x: preprocessing(x) if type(x) == str else None)\n",
    "data.artist_perf = data.artist_perf.apply(lambda x: preprocessing(x) if type(x) == str else None)\n",
    "data.composer = data.composer.apply(lambda x: preprocessing(x) if type(x) == str else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AW1_correct(row):\n",
    "    if row.AW1 and row.artist_original:\n",
    "        aws = row.AW1.split()\n",
    "        return any([aw.lower() in [a.lower() for a in row.artist_original.split()] for aw in aws])\n",
    "    return\n",
    "\n",
    "def artist_partly_correct(row, answer_col: str):\n",
    "    if row[answer_col] and row.performer:\n",
    "        artists = row[answer_col].split()\n",
    "        if row.artist_original:\n",
    "            artists += row.artist_original.split()\n",
    "        if row.composer:\n",
    "            artists += row.composer.split()\n",
    "        for artist in artists:\n",
    "            for performer in row.performer:\n",
    "                if artist in performer:\n",
    "                    return True\n",
    "    else: \n",
    "        return None\n",
    "    return False\n",
    "\n",
    "def AW2_correct(row):\n",
    "    if row.AW2 and row.artist_perf:\n",
    "        aws = row.AW2.split()\n",
    "        return any([aw.lower() in [a.lower() for a in row.artist_perf.split()] for aw in aws])\n",
    "    return\n",
    "\n",
    "def AW3_correct(row):\n",
    "    if row.AW3 and row.composer:\n",
    "        aws = row.AW3.split()\n",
    "        return any([aw.lower() in [c.lower() for c in row.composer.split()] for aw in aws])\n",
    "    return\n",
    "\n",
    "data[\"AW1: Correct\"] = data.apply(AW1_correct, axis=1)\n",
    "data[\"AW1: Related\"] = data.apply(lambda x: artist_partly_correct(x, \"AW1\"), axis=1)\n",
    "\n",
    "data[\"AW2: Correct\"] = data.apply(AW2_correct, axis=1)\n",
    "data[\"AW2: Related\"] = data.apply(lambda x: artist_partly_correct(x, \"AW2\"), axis=1)\n",
    "\n",
    "data[\"AW3: Correct\"] = data.apply(AW3_correct, axis=1)\n",
    "data[\"AW3: Related\"] = data.apply(lambda x: artist_partly_correct(x, \"AW3\"), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_cols = ['set_id', 'work_id', 'perf_id', 'Model']\n",
    "aw_cols = [col for col in data.columns if col.startswith('AW') and \":\" in col]\n",
    "\n",
    "data[id_cols + aw_cols]\n",
    "\n",
    "data_melted = data.melt(id_vars=id_cols, value_vars=aw_cols)\n",
    "\n",
    "data_melted_pivoted = data_melted.pivot_table(\n",
    "    index=['set_id', 'work_id', 'perf_id'],\n",
    "    columns=['Model', 'variable'],\n",
    "    values='value',\n",
    "    aggfunc='first'  # 'first' because we assume there is no aggregation needed if values are unique\n",
    ")\n",
    "data_melted_pivoted.reset_index().to_json(\"../data/intermediate/shs100k2_memorization.jsonl\", lines=True, orient=\"records\")\n",
    "data_melted_pivoted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "__data = data_melted_pivoted.sum().unstack(level=0) \n",
    "prob = lambda x: x / data.set_id.nunique()\n",
    "__data = __data.apply(prob)\n",
    "__data.plot(kind=\"bar\")\n",
    "\n",
    "plt.xticks(rotation=15)\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2)\n",
    "plt.savefig(\"../figures/memorization_test.pdf\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
