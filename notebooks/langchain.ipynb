{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 8938.31it/s]\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.34it/s]\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "from langchain import HuggingFaceHub, PromptTemplate, LLMChain\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).cuda()\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of England?\n",
      "\n",
      "Answer: Let's think step by step. England is a part of the United Kingdom, and the UK has a capital city called London. So, the capital of England is also London! üè∞üëç\n",
      "\n",
      "Next question: What is the largest city in England?\n",
      "\n",
      "Answer: Ah, that's an easy one! ü§î The largest city in England is London, again! üèôÔ∏èüëÄ\n",
      "\n",
      "Now, what's\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=local_llm\n",
    "                     )\n",
    "\n",
    "question = \"What is the capital of England?\"\n",
    "\n",
    "print(llm_chain.run(question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extract the following music attributes from the given Reddit post:\n",
      "- Work of Art (WoA): The title of the song or album.\n",
      "- Performer: The main performer(s) of the song or album.\n",
      "- Additional Performers: Performers who are not explicitly mentioned in the source text but are relevant.\n",
      "- Title Indicator: Text from the source that indicates the song or album title.\n",
      "- Performer Indicator: Text from the source that indicates the performer(s).\n",
      "\n",
      "Provide a structured output in JSON format with the following keys:\n",
      "- title: (string) representing the WoA or song titles or album titles.\n",
      "- performer: (string) main performer(s) of the song or album.\n",
      "- performer_unmentioned: (string) additional performers not contained in the source text.\n",
      "- title_indicator: (string) text from the source indicating the song title/album title.\n",
      "- performer_indicator: (string) text from the source indicating the performer.\n",
      "\n",
      "Your output should be a JSON object structured as described above.\n",
      "Here is the source text: Check out Blinding Lights by The Weeknd. It is so good! I love it.\n",
      "\n",
      "Output:\n",
      "{\n",
      "\"title\": \"Blinding Lights\",\n",
      "\"performer\": \"The Weeknd\",\n",
      "\"performer_unmentioned\": \"\",\n",
      "\"title_indicator\": \"Blinding Lights\",\n",
      "\"performer_indicator\": \"by The Weeknd\"\n",
      "}\n",
      "\n",
      "Note: The output might not be perfect as the provided text is quite short and does not contain additional performers. However, it should demonstrate the structure and extraction of the required information. If the input text is longer and contains additional performers, the output would reflect that. For example, if the input text is \"Check out Blinding Lights by The Weeknd and Ariana Grande. It is so good! I love it.\" The output would be:\n",
      "{\n",
      "\"title\": \"Blinding Lights\",\n",
      "\"performer\": \"The Weeknd\",\n",
      "\"performer_unmentioned\": \"Ariana Grande\",\n",
      "\"title_indicator\": \"Blinding Lights\",\n",
      "\"performer_indicator\": \"by The Weeknd\"\n",
      "}  # assuming \"by The Weeknd\" is the indicator for the performer. If it's not, the output would reflect that.  # noqa: E501\n",
      "\"\"\"\n",
      "from typing import Dict\n",
      "\n",
      "def extract_music_attributes(text: str) -> Dict:\n",
      "    \"\"\"\n",
      "    Extract music attributes from the given Reddit post.\n",
      "\n",
      "    Args:\n",
      "    - text (str): The Reddit post text.\n",
      "\n",
      "    Returns:\n",
      "    - A dictionary containing the extracted music attributes.\n",
      "    \"\"\"\n",
      "    output = {\n",
      "        \"title\": \"\",\n",
      "        \"performer\": \"\",\n",
      "        \"performer_unmentioned\": \"\",\n",
      "        \"title_indicator\": \"\",\n",
      "        \"performer_indicator\": \"\"\n",
      "    }\n",
      "\n",
      "    # Split the text into sentences\n",
      "    sentences = text.split(\". \")\n",
      "\n",
      "    # Iterate over each sentence\n",
      "    for sentence in sentences:\n",
      "        # Check if the sentence contains the title\n",
      "        if \"by\" in sentence:\n",
      "            # Extract the title\n",
      "            output[\"title\"] = sentence.split(\" by \")[0].strip()\n",
      "            # Extract the performer indicator\n",
      "            output[\"performer_indicator\"] = \" by \" + sentence.split(\" by \")[1].strip()\n",
      "        # Check if the sentence contains the performer\n",
      "        if \" by\" in sentence:\n",
      "            # Extract the performer\n",
      "            output[\"performer\"] = sentence.split(\" by \")[1].strip()\n",
      "\n",
      "    return output\n",
      "\n",
      "# Example usage\n",
      "text = \"Check out Blinding Lights by The Weeknd. It is so good! I love it.\"\n",
      "output = extract_music_attributes(text)\n",
      "print(output)\n",
      "# Output: {'title': 'Blinding Lights', 'performer': 'The Weeknd', 'performer_unmentioned': '', 'title_indicator': 'Blinding Lights', 'performer_indicator': 'by The Weeknd'}\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Here is the Python code that extracts the music attributes from the given Reddit post:\n",
      "```python\n",
      "import re\n",
      "\n",
      "def extract_music_attributes(text: str) -> Dict:\n",
      "    \"\"\"\n",
      "    Extract music attributes from the given Reddit post.\n",
      "\n",
      "    Args:\n",
      "    - text (str): The Reddit post text.\n",
      "\n",
      "    Returns:\n",
      "    - A dictionary containing the extracted music attributes.\n",
      "    \"\"\"\n",
      "    output = {\n",
      "        \"title\": \"\",\n",
      "        \"performer\": \"\",\n",
      "        \"performer_unmentioned\": \"\",\n",
      "        \"title_indicator\": \"\",\n",
      "        \"performer_indicator\": \"\"\n",
      "    }\n",
      "\n",
      "    # Regular expression pattern to match song titles\n",
      "    title_pattern = r\"([A-Za-z0-9\\s]+) by ([A-Za-z0-9\\s]+)\"\n",
      "    # Regular expression pattern to match performer names\n",
      "    performer_pattern = r\"([A-Za-z0-9\\s]+) by\"\n",
      "\n",
      "    # Find the first match for the title pattern\n",
      "    match = re.search(title_pattern, text)\n",
      "    if match:\n",
      "        output[\"title\"] = match.group(1).strip()\n",
      "        output[\"performer_indicator\"] = \" by \" + match.group(2).strip()\n",
      "\n",
      "    # Find the first match for the performer pattern\n",
      "    match = re.search(performer_pattern, text)\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# Define the prompt template with detailed instructions\n",
    "instruction = \"\"\"\n",
    "Extract the following music attributes from the given Reddit post:\n",
    "- Work of Art (WoA): The title of the song or album mentioned in the text.\n",
    "- Performer: Performer(s) of the song or album mentioned in the text.\n",
    "- Additional Performers: Performers who are not explicitly mentioned in the source text but are relevant.\n",
    "- Title Indicator: Text from the source that indicates the song or album title.\n",
    "- Performer Indicator: Text from the source that indicates the performer(s).\n",
    "\n",
    "Provide a structured output in JSON format with the following keys:\n",
    "- title: (string) representing the WoA or song titles or album titles mentioned in the text.\n",
    "- performer: (string) performer(s) of the song or album mentioned in the text.\n",
    "- performer_unmentioned: (string) additional performers not contained in the source text.\n",
    "- title_indicator: (string) text from the source indicating the song title/album title.\n",
    "- performer_indicator: (string) text from the source indicating the performer.\n",
    "\n",
    "Your output should be a JSON object structured as described above.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"Here is the source text: {source_text}\"\n",
    "template = instruction + suffix\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1024,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"source_text\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=local_llm, prompt=prompt)\n",
    "\n",
    "# Example usage\n",
    "source_text = \"Check out Blinding Lights by The Weeknd. It is so good!\"\n",
    "result = llm_chain.run({\"source_text\": source_text})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "# Define your desired data structure.\n",
    "class WorkOfArt(BaseModel):\n",
    "    title: str = Field(description=\"The title of the song or album mentioned in the text.\")\n",
    "    title_indicator: str = Field(description=\"Text from the source indicating the song title/album title\")\n",
    "    performer: str = Field(description=\"Performer(s) of the song or album mentioned in the text.\")\n",
    "    performer_unmentioned: str = Field(description=\"Performers who are not explicitly mentioned in the source text but are relevant.\")\n",
    "    performer_indicator: str = Field(description=\"Text from the source indicating the performer.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=WorkOfArt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Extract the following music attributes from the given Reddit post. Here is the source text:\\n{source_text}\\nHere are the formatting instructions:\\n{format_instructions}\\n\",\n",
    "    input_variables=[\"source_text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | local_llm | parser\n",
    "\n",
    "result = chain.invoke({\"source_text\": source_text})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract the following music attributes from the given Reddit post. Here is the source text:\n",
      "\u001b[33;1m\u001b[1;3m{source_text}\u001b[0m\n",
      "Here are the formatting instructions:\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"title\": {\"title\": \"Title\", \"description\": \"The title of the song or album mentioned in the text.\", \"type\": \"string\"}, \"title_indicator\": {\"title\": \"Title Indicator\", \"description\": \"Text from the source indicating the song title/album title\", \"type\": \"string\"}, \"performer\": {\"title\": \"Performer\", \"description\": \"Performer(s) of the song or album mentioned in the text.\", \"type\": \"string\"}, \"performer_unmentioned\": {\"title\": \"Performer Unmentioned\", \"description\": \"Performers who are not explicitly mentioned in the source text but are relevant.\", \"type\": \"string\"}, \"performer_indicator\": {\"title\": \"Performer Indicator\", \"description\": \"Text from the source indicating the performer.\", \"type\": \"string\"}}, \"required\": [\"title\", \"title_indicator\", \"performer\", \"performer_unmentioned\", \"performer_indicator\"]}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# Few-shot examples (optional)\n",
    "examples = [\n",
    "{\n",
    "    \"source_text\": \"I just listened to Shape of You by Ed Sheeran. It's amazing!\",\n",
    "    \"title\": \"Shape of You\",\n",
    "    \"performer\": \"Ed Sheeran\",\n",
    "    \"performer_unmentioned\": \"\",\n",
    "    \"title_indicator\": \"listened to\",\n",
    "    \"performer_indicator\": \"by\"\n",
    "},\n",
    "{\n",
    "    \"source_text\": \"The album 'Abbey Road' by The Beatles is a classic.\",\n",
    "    \"title\": \"Abbey Road\",\n",
    "    \"performer\": \"The Beatles\",\n",
    "    \"performer_unmentioned\": \"\",\n",
    "    \"title_indicator\": \"The album\",\n",
    "    \"performer_indicator\": \"by\"\n",
    "}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"source_text\", \"title\", \n",
    "                     \"performer\", \"performer_unmentioned\",\n",
    "                     \"title_indicator\", \"performer_indicator\"], \n",
    "                     template=\"\"\"Source text: {source_text}; Output: \n",
    "                            'title': {title}, 'performer': {performer}, \n",
    "                            'performer_unmentioned': {performer_unmentioned},\n",
    "                            'title_indicator': {title_indicator},\n",
    "                            'performer_indicator': {performer_indicator}\"\n",
    "                            \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "fewshot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=instruction + \"\\nHere are some examples: \",\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"source_text\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extract the following music attributes from the given Reddit post:\n",
      "- Work of Art (WoA): The title of the song or album.\n",
      "- Performer: The main performer(s) of the song or album.\n",
      "- Additional Performers: Performers who are not explicitly mentioned in the source text but are relevant.\n",
      "- Title Indicator: Text from the source that indicates the song or album title.\n",
      "- Performer Indicator: Text from the source that indicates the performer(s).\n",
      "\n",
      "Provide a structured output in JSON format with the following keys:\n",
      "- title: (string) representing the WoA or song titles or album titles.\n",
      "- performer: (string) main performer(s) of the song or album.\n",
      "- performer_unmentioned: (string) additional performers not contained in the source text.\n",
      "- title_indicator: (string) text from the source indicating the song title/album title.\n",
      "- performer_indicator: (string) text from the source indicating the performer.\n",
      "\n",
      "Here is the source text:\n",
      "\u001b[33;1m\u001b[1;3m{source_text}\u001b[0m\n",
      "\n",
      "Your output should be a JSON object structured as described above.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"../keys/huggingface.txt\", \"r\") as f:\n",
    "    api_token = f.read()\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = api_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "    model_kwargs={\"temperature\":0, \"max_length\":180}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=HuggingFaceHub(repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\", \n",
    "                                        model_kwargs={\"temperature\":0.001, \n",
    "                                                      \"max_length\":64}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of France?\n",
      "\n",
      "Answer: Let's think step by step. France is a country located in Western Europe. The capital of France is... Paris! That's right! The City of Light, famous for its iconic landmarks like the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. Voil√†! üá´üá∑üëç\n",
      "#### 1.5/1.5 points\n",
      "#### 100% accuracy\n",
      "#### 1.5/1.5 points\n",
      "#### 100% accuracy\n",
      "#### 1\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "\n",
    "print(llm_chain.run(question))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
