{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_parquet(\"../data/dataset/reddit+shsyt/data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Tokens: ['Hello', 'Jane', 'Smith', 'from', 'Los', 'Angeles', 'California']\n",
      "New IOB Tags: ['O', 'B-PER', 'I-PER', 'O', 'B-LOC', 'I-LOC', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def replace_utterances(iob_tags, tokens, class_dict):\n",
    "    \"\"\"\n",
    "    Replaces the utterances in tokens based on the IOB tags with random utterances from the provided class_dict.\n",
    "\n",
    "    Parameters:\n",
    "    iob_tags (list of str): A list of IOB tags.\n",
    "    tokens (list of str): A list of corresponding tokens/words.\n",
    "    class_dict (dict): A dictionary mapping class names (keys) to lists of possible replacement utterances.\n",
    "\n",
    "    Returns:\n",
    "    list of str: The modified list of tokens with replaced utterances.\n",
    "    list of str: The modified list of IOB tags corresponding to the new tokens.\n",
    "    \"\"\"\n",
    "    new_tokens = []\n",
    "    new_iob_tags = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(iob_tags):\n",
    "        if iob_tags[i].startswith('B-'):\n",
    "            class_label = iob_tags[i][2:]  # Get the class label without the \"B-\" prefix\n",
    "            utterance_list = class_dict.get(class_label, [tokens[i]])  # Get the replacement list or the original token\n",
    "            \n",
    "            # Select a random replacement utterance\n",
    "            replacement = random.choice(utterance_list)\n",
    "            replacement_tokens = replacement.split()  # Split the replacement into tokens\n",
    "            \n",
    "            # Add the replacement tokens to the new list\n",
    "            new_tokens.extend(replacement_tokens)\n",
    "            \n",
    "            # Add corresponding IOB tags for the replacement tokens\n",
    "            new_iob_tags.append(f'B-{class_label}')\n",
    "            for _ in range(1, len(replacement_tokens)):\n",
    "                new_iob_tags.append(f'I-{class_label}')\n",
    "            \n",
    "            # Skip the original utterance tokens\n",
    "            while i < len(iob_tags) and iob_tags[i].startswith(('B-', 'I-')):\n",
    "                i += 1\n",
    "        else:\n",
    "            new_tokens.append(tokens[i])\n",
    "            new_iob_tags.append(iob_tags[i])\n",
    "            i += 1\n",
    "    \n",
    "    return new_tokens, new_iob_tags\n",
    "\n",
    "# Example usage:\n",
    "iob_tags = ['O', 'B-PER', 'I-PER', 'O', 'B-LOC', 'I-LOC']\n",
    "tokens = ['Hello', 'John', 'Doe', 'from', 'New', 'York']\n",
    "class_dict = {\n",
    "    'PER': ['Jane Smith', 'Alice Johnson'],\n",
    "    'LOC': ['San Francisco', 'Los Angeles California']\n",
    "}\n",
    "\n",
    "new_tokens, new_iob_tags = replace_utterances(iob_tags, tokens, class_dict)\n",
    "print(\"New Tokens:\", new_tokens)\n",
    "print(\"New IOB Tags:\", new_iob_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def perturb_characters(text, num_chars_to_perturb):\n",
    "    \"\"\"\n",
    "    Perturb a specific number of characters in the input text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The original text to perturb.\n",
    "        num_chars_to_perturb (int): The number of characters to perturb.\n",
    "        \n",
    "    Returns:\n",
    "        str: The perturbed text.\n",
    "    \"\"\"\n",
    "    characters = list(text)\n",
    "    text_length = len(characters)\n",
    "\n",
    "    if num_chars_to_perturb > text_length:\n",
    "        num_chars_to_perturb = text_length\n",
    "\n",
    "    for _ in range(num_chars_to_perturb):\n",
    "        perturbation_type = random.choice([\"substitution\", \"deletion\", \"insertion\"])\n",
    "        index = random.randint(0, len(characters) - 1)\n",
    "        \n",
    "        if perturbation_type == \"substitution\":\n",
    "            # Replace the character with a random one\n",
    "            characters[index] = random.choice(\"abcdefghijklmnopqrstuvwxyz-./_=\")\n",
    "        elif perturbation_type == \"deletion\" and len(characters) > 1:\n",
    "            # Remove the character\n",
    "            characters.pop(index)\n",
    "        elif perturbation_type == \"insertion\":\n",
    "            # Insert a random character\n",
    "            characters.insert(index, random.choice(\"abcdefghijklmnopqrstuvwxyz-./=\"))\n",
    "    \n",
    "    return ''.join(characters)\n",
    "\n",
    "\n",
    "def perturb_tokens(text, perturbation_strength=0.1):\n",
    "    \"\"\"\n",
    "    Perturb tokens in the input text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The original text to perturb.\n",
    "        perturbation_strength (float): The proportion of tokens to perturb (0 to 1).\n",
    "        \n",
    "    Returns:\n",
    "        str: The perturbed text.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    num_perturbations = int(len(tokens) * perturbation_strength)\n",
    "    \n",
    "    for _ in range(num_perturbations):\n",
    "        perturbation_type = random.choice([\"substitution\", \"deletion\", \"shuffle\"])\n",
    "        index = random.randint(0, len(tokens) - 1)\n",
    "        \n",
    "        if perturbation_type == \"substitution\":\n",
    "            # Replace the token with a random one (for simplicity, replacing with \"RANDOM\" token)\n",
    "            tokens[index] = \"RANDOM\"\n",
    "        elif perturbation_type == \"deletion\" and len(tokens) > 1:\n",
    "            # Remove the token\n",
    "            tokens.pop(index)\n",
    "        elif perturbation_type == \"shuffle\" and len(tokens) > 1:\n",
    "            # Shuffle the token with another random token\n",
    "            swap_index = random.randint(0, len(tokens) - 1)\n",
    "            tokens[index], tokens[swap_index] = tokens[swap_index], tokens[index]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lThe beatles'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb_characters(\"The beatles\", num_chars_to_perturb=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This an example text.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"This is an example text.\"\n",
    "perturbed_text = perturb_tokens(text, perturbation_strength=0.2)\n",
    "print(perturbed_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
