{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.llama_api import LlamaAPI\n",
    "\n",
    "with open(\"../keys/llama.txt\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "llm_llama = LlamaAPI(api_key=api_key, temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "with open(\"../keys/openai.txt\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "model = \"gpt-3.5-turbo-0125\"\n",
    "llm_openai = OpenAI(model=model, api_key=api_key, temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Label(str, Enum):\n",
    "    title = 'title'\n",
    "    performer = 'performer'\n",
    "\n",
    "class MusicEntity(BaseModel):\n",
    "    \"\"\"Data model of a music entity\"\"\"\n",
    "    utterance: str \n",
    "    label: Label\n",
    "    cue: str\n",
    "\n",
    "    class Config:  \n",
    "        use_enum_values = True\n",
    "        \n",
    "class EntityList(BaseModel):\n",
    "    \"\"\"Data model for list of music entities.\"\"\"\n",
    "    content: List[MusicEntity]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.program.openai import OpenAIPydanticProgram\n",
    "\n",
    "prompt_template_str = \"\"\"\\\n",
    "From the following text which contains a user requests for music suggestions, extract all the music entities.\n",
    "A music entity has the following attributes:\n",
    "    - utterance: The utterance of the entity in the text. For example \"the beatles\" in \"recommend me music like the beatles\".\n",
    "    - label: The label of the entity. It can either be 'title' (eg. a song title, an album title, a symphony) or it can be 'performer' which refers to a performing musical artist.\n",
    "    - cue: The contextual cue which indicates the musical entity (eg. \"music like\" in \"recommend me music like the beatles\" indicating \"the beatles\")\n",
    "Here is the text: {text}\n",
    "\"\"\"\n",
    "\n",
    "program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=EntityList,\n",
    "    llm=llm_openai,\n",
    "    prompt_template_str=prompt_template_str,\n",
    "    allow_multiple=False,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "from src.Utils import read_IOB_file, transform_to_dict, write_jsonlines\n",
    "import os \n",
    "\n",
    "# load data\n",
    "dataset_id = str(1)\n",
    "data_path = f\"../baseline/music-ner-eacl2023/data/dataset{dataset_id}/test.bio\"\n",
    "texts, labels = read_IOB_file(data_path)\n",
    "\n",
    "outputs = []\n",
    "for tokens, iob in tqdm(zip(texts, labels)):\n",
    "\n",
    "    text = ' '.join(tokens)\n",
    "    true_ents = transform_to_dict(tokens, iob)\n",
    "\n",
    "    # put input data and true entities\n",
    "    output = {}\n",
    "    output[\"text\"] = text\n",
    "    output[\"performers\"] = true_ents.get(\"Artist\") or []\n",
    "    output[\"titles\"] = true_ents.get(\"WoA\") or []\n",
    "\n",
    "    # extract with LLM\n",
    "    ent_list = program(text=text)\n",
    "    llm_ents = [ent.model_dump() for ent in ent_list.content]\n",
    "    output[\"extracted\"] = llm_ents\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "# write output    \n",
    "output_dir = os.path.join(\"..\", \"output\", model)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "write_jsonlines(output_dir + os.sep + f\"reddit{dataset_id}.jsonl\", outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot with Mixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just runs .complete to make sure the LLM is listening\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.program import LLMTextCompletionProgram\n",
    "from llama_index.core import PromptTemplate\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.Utils import read_IOB_file, transform_to_dict, write_jsonlines\n",
    "\n",
    "# init model\n",
    "llm_mixtral = Ollama(model=\"mixtral\")\n",
    "\n",
    "# load data\n",
    "dataset_id = str(1)\n",
    "test_path = f\"../baseline/music-ner-eacl2023/data/dataset{dataset_id}/test.bio\"\n",
    "texts_test, labels_test = read_IOB_file(test_path)\n",
    "\n",
    "dataset_id = str(1)\n",
    "train_path = f\"../baseline/music-ner-eacl2023/data/dataset{dataset_id}/train.bio\"\n",
    "texts_train, labels_train = read_IOB_file(train_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Few-Shot Dataset from Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Example(BaseModel):\n",
    "    \"\"\"\n",
    "    Data model for a few-shot example.\n",
    "    \"\"\"\n",
    "    text: str\n",
    "    output: EntityList\n",
    "\n",
    "def entity_dict_to_pydantic(entity_dict: dict) -> EntityList:\n",
    "\n",
    "    entity_list = EntityList(content=[])\n",
    "\n",
    "    entity_dict[\"title\"] = entity_dict.get(\"WoA\")\n",
    "    entity_dict[\"performer\"] = entity_dict.get(\"Artist\")\n",
    "    for key in [\"title\", \"performer\"]:\n",
    "        if entity_dict.get(key):\n",
    "            for value in entity_dict[key]:\n",
    "                entity_list.content.append(MusicEntity(utterance=value, label=key, cue=\"\"))\n",
    "    return entity_list\n",
    "\n",
    "examples = []\n",
    "\n",
    "for tokens, iob in zip(texts_train, labels_train):\n",
    "    true_ents = transform_to_dict(tokens, iob)\n",
    "    text = ' '.join(tokens)\n",
    "    entity_list = entity_dict_to_pydantic(true_ents)\n",
    "    examples.append(Example(text=text, output=entity_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "prompt_template_str = \"\"\"\\\n",
    "From the following text which contains a user requests for music suggestions, extract all the music entities.\n",
    "A music entity has the following attributes:\n",
    "    - utterance: The utterance of the entity in the text. For example \"the beatles\" in \"recommend me music like the beatles\".\n",
    "    - label: The label of the entity. It can either be 'title' (eg. a song title, an album title, a symphony) or it can be 'performer' which refers to a performing musical artist.\n",
    "    - cue: The contextual cue which indicates the musical entity (eg. \"music like\" in \"recommend me music like the beatles\" indicating \"the beatles\")\n",
    "\n",
    "Here are {k} examples: \n",
    "{few_shot_examples}\n",
    "    \n",
    "Here is the text: {text}\n",
    "\"\"\"\n",
    "\n",
    "def few_shot_examples_random(**kwargs):\n",
    "    k = kwargs[\"k\"]\n",
    "    few_shot_examples = random.sample(examples, k)\n",
    "    # go through each node, get json object\n",
    "\n",
    "    result_strs = []\n",
    "    for example in few_shot_examples:\n",
    "        result_str = f\"\"\"\\\n",
    "Text: {example.text}\n",
    "Response: {example.output.model_dump()}\"\"\"\n",
    "        result_strs.append(result_str)\n",
    "    return \"\\n\\n\".join(result_strs)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    prompt_template_str,\n",
    "    function_mappings={\"few_shot_examples\": few_shot_examples_random},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = LLMTextCompletionProgram.from_defaults(\n",
    "    output_cls=EntityList,\n",
    "    llm=llm_mixtral,\n",
    "    prompt=prompt_template,\n",
    "    allow_multiple=False,\n",
    "    verbose=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
