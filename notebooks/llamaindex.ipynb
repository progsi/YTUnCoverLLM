{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.llama_api import LlamaAPI\n",
    "\n",
    "with open(\"../keys/llama.txt\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "llm_llama = LlamaAPI(api_key=api_key, temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "with open(\"../keys/openai.txt\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "model = \"gpt-3.5-turbo-0125\"\n",
    "llm_openai = OpenAI(model=model, api_key=api_key, temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Label(str, Enum):\n",
    "    title = 'title'\n",
    "    performer = 'performer'\n",
    "\n",
    "class MusicEntity(BaseModel):\n",
    "    \"\"\"Data model of a music entity\"\"\"\n",
    "    utterance: str \n",
    "    label: Label\n",
    "    cue: str\n",
    "\n",
    "    class Config:  \n",
    "        use_enum_values = True\n",
    "        \n",
    "class EntityList(BaseModel):\n",
    "    \"\"\"Data model for list of music entities.\"\"\"\n",
    "    content: List[MusicEntity]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.program.openai import OpenAIPydanticProgram\n",
    "\n",
    "prompt_template = \"\"\"\\\n",
    "From the following text which contains a user requests for music suggestions, extract all the music entities.\n",
    "A music entity has the following attributes:\n",
    "    - utterance: The utterance of the entity in the text. For example \"the beatles\" in \"recommend me music like the beatles\".\n",
    "    - label: The label of the entity. It can either be 'title' (eg. a song title, an album title, a symphony) or it can be 'performer' which refers to a performing musical artist.\n",
    "    - cue: The contextual cue which indicates the musical entity (eg. \"music like\" in \"recommend me music like the beatles\" indicating \"the beatles\")\n",
    "Here is the text: {text}\n",
    "\"\"\"\n",
    "\n",
    "program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=EntityList,\n",
    "    llm=llm_openai,\n",
    "    prompt_template_str=prompt_template,\n",
    "    allow_multiple=False,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "from src.Utils import read_IOB_file, transform_to_dict, write_jsonlines\n",
    "import os \n",
    "\n",
    "# load data\n",
    "dataset_id = str(1)\n",
    "data_path = f\"../baseline/music-ner-eacl2023/data/dataset{dataset_id}/test.bio\"\n",
    "texts, labels = read_IOB_file(data_path)\n",
    "\n",
    "outputs = []\n",
    "for tokens, iob in tqdm(zip(texts, labels)):\n",
    "\n",
    "    text = ' '.join(tokens)\n",
    "    true_ents = transform_to_dict(tokens, iob)\n",
    "\n",
    "    # put input data and true entities\n",
    "    output = {}\n",
    "    output[\"text\"] = text\n",
    "    output[\"performers\"] = true_ents.get(\"Artist\") or []\n",
    "    output[\"titles\"] = true_ents.get(\"WoA\") or []\n",
    "\n",
    "    # extract with LLM\n",
    "    ent_list = program(text=text)\n",
    "    llm_ents = [ent.model_dump() for ent in ent_list.content]\n",
    "    output[\"extracted\"] = llm_ents\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "# write output    \n",
    "output_dir = os.path.join(\"..\", \"output\", model)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "write_jsonlines(output_dir + os.sep + f\"reddit{dataset_id}.jsonl\", outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just runs .complete to make sure the LLM is listening\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.program import FunctionCallingProgram, LLMTextCompletionProgram\n",
    "\n",
    "llm_mixtral = Ollama(model=\"mixtral\")\n",
    "\n",
    "program = LLMTextCompletionProgram.from_defaults(\n",
    "    output_cls=EntityList,\n",
    "    llm=llm_mixtral,\n",
    "    prompt_template_str=prompt_template,\n",
    "    allow_multiple=False,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
